import paddle
import paddle.fluid as fluid
import paddle.fluid.dygraph as dygraph
from paddle.fluid.dygraph import Linear
import numpy as np
import os
import random

import numpy as np
import json
datafile = './jump.data'
data = np.fromfile(datafile, sep=' ')
data
array([6.320e-03, 1.800e+01, 2.310e+00, ..., 3.969e+02, 7.880e+00,
       1.190e+01])
       
feature_names = [ 'jump', '30s', 'third', 'preparerun', 'weigth', 'squat', '100m','hold', 
                 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]
feature_num = len(feature_names)
data = data.reshape([data.shape[0] // feature_num, feature_num])

x = data[0]
print(x.shape)
print(x)

ratio = 0.9
offset = int(data.shape[0] * ratio)
training_data = data[:offset]
training_data.shape

maximums, minimums, avgs = \
                     training_data.max(axis=0), \
                     training_data.min(axis=0), \
     training_data.sum(axis=0) / training_data.shape[0]

for i in range(feature_num):
    #print(maximums[i], minimums[i], avgs[i])
    data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])
    
    
    
    
    def load_data():
    datafile = './jump.data'
    data = np.fromfile(datafile, sep=' ')

    feature_names = [ 'jump', '30s', 'third', 'preparerun', 'weigth', 'squat', '100m','hold' 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]
    feature_num = len(feature_names)

    data = data.reshape([data.shape[0] // feature_num, feature_num])
    
    ratio = 0.9
    offset = int(data.shape[0] * ratio)
    training_data = data[:offset]

    
    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0), \
                                 training_data.sum(axis=0) / training_data.shape[0]
 

    global max_values
    global min_values
    global avg_values
    max_values = maximums
    min_values = minimums
    avg_values = avgs

    for i in range(feature_num):
        #print(maximums[i], minimums[i], avgs[i])
        data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])

    #ratio = 0.9
    #offset = int(data.shape[0] * ratio)
    training_data = data[:offset]
    test_data = data[offset:]
    return training_data, test_data
    
    class Regressor(fluid.dygraph.Layer):
    def __init__(self):
        super(Regressor, self).__init__()
        
        self.fc = Linear(input_dim=13, output_dim=1, act=None)
    
    def forward(self, inputs):
        x = self.fc(inputs)
        return x
        
        with fluid.dygraph.guard():
    model = Regressor()
    model.train()
    training_data, test_data = load_data()
    opt = fluid.optimizer.SGD(learning_rate=0.01, parameter_list=model.parameters())
    
     for iter_id, mini_batch in enumerate(mini_batches):
      for epoch_id in range(EPOCH_NUM):
      with dygraph.guard(fluid.CPUPlace()):
    EPOCH_NUM = 10   
    BATCH_SIZE = 10 
    

    for epoch_id in range(EPOCH_NUM):
        np.random.shuffle(training_data)
        mini_batches = [training_data[k:k+BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]
        for iter_id, mini_batch in enumerate(mini_batches):
            x = np.array(mini_batch[:, :-1]).astype('float32')
            y = np.array(mini_batch[:, -1:]).astype('float32') 
            house_features = dygraph.to_variable(x)
            grade = dygraph.to_variable(y)
            predicts = model(house_features)
           
            loss = fluid.layers.square_error_cost(predicts, label=prices)
            avg_loss = fluid.layers.mean(loss)
            if iter_id%20==0:
                print("epoch: {}, iter: {}, loss is: {}".format(epoch_id, iter_id, avg_loss.numpy()))
            avg_loss.backward()
            opt.minimize(avg_loss)
            model.clear_gradients()
    fluid.save_dygraph(model.state_dict(), 'LR_model')
